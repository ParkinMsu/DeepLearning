{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Все места, где нужно дописать код отмечены TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считывание и подготовка данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Считываем данные: каждый класс лежит в своем csv файле. \n",
    "male = pd.read_csv('male.csv',header = None)[0]\n",
    "female = pd.read_csv('female.csv',header = None)[0]\n",
    "\n",
    "y = np.hstack((np.zeros(len(male)),np.ones(len(female))))\n",
    "data = list(male)\n",
    "data.extend(list(female))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Для дальнейшей работы нам понадобится словарь символов + \n",
    "# мы не будем различать строчные и прописные буквы + \n",
    "# у нас все последовательности разной длины и нам нужно понимать, какова макимальная длина\n",
    "MAX_LEN = 0\n",
    "chars = set()\n",
    "for i in xrange(len(data)):\n",
    "    data[i] = data[i].lower()\n",
    "    MAX_LEN = max(MAX_LEN,len(data[i]))\n",
    "    chars = chars.union(set(data[i][:]))\n",
    "\n",
    "chars = list(chars)\n",
    "#Добавим символы начала('@') и конца('$')\n",
    "MAX_LEN += 2\n",
    "chars.append('@')\n",
    "chars.append('$')\n",
    "\n",
    "char_to_id = { ch:id for id,ch in enumerate(chars) }\n",
    "id_to_char = { id:ch for id,ch in enumerate(chars) }\n",
    "\n",
    "VOCAB_SIZE = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Разделим выборку на трейн и тест\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data2format(data, labels):\n",
    "    \"\"\"Функция преобразует выбоку данных в формат, подходящий для подачи в нейронную сеть.\n",
    "    \n",
    "    data - список строк (пример - X_train)\n",
    "    labels - вектор меток для строк из data (пример - y_train)\n",
    "    \n",
    "    Дальше за N обозначается число строк в data\n",
    "    \n",
    "    Вернуть нужно словарь со следующими элементами:\n",
    "    x - матрица размера [N, MAX_LEN], в которой каждая строка соответствует строке в data:\n",
    "        к строке прибавляется символы начала и конца строки, \n",
    "        после чего вся строка кодируется с помощью char_to_id.\n",
    "        Недостающие элементы в конце коротких строк заполняются нулями\n",
    "    mask - бинарная матрица размера [N, MAX_LEN]:\n",
    "        единица говорит о том, что в соответствующем элементе x стоит значащий символ\n",
    "        ноль говорит о том, что соответствующий элемент x не несет информации \n",
    "        (те самые нули, которые просто дополняют строки до MAX_LEN)\n",
    "    y - вектор длины N с метками\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    N = len(data)\n",
    "    X = np.zeros((N,MAX_LEN))\n",
    "    mask = np.zeros((N, MAX_LEN), dtype='int32')\n",
    "    for idx,row in enumerate(data):\n",
    "        row = '@' + row + '$'\n",
    "        X[idx,:len(row)] = [char_to_id.get(x,0) for x in row]\n",
    "        mask[idx,:len(row)] = [1 for _ in row]\n",
    "        \n",
    "    return {'x':X,'mask': mask,'y': np.array(y,dtype='int32')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = data2format(X_train,y_train)\n",
    "test_data = data2format(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Необходимые константы\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 100\n",
    "SEQ_LEN = 20\n",
    "LEARNING_RATE = 0.01\n",
    "GRAD_CLIP = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Технические вещи\n",
    "\n",
    "# Вспомогательная функция для запаковки результата обучения \n",
    "def pack(train_err, train_acc, test_err,test_acc, network, inp, inp_mask,target,train_fn, test_fn):\n",
    "    return {'train_err':train_err, \n",
    "        'train_acc':train_acc, \n",
    "        'test_err':test_err, \n",
    "        'test_acc':test_acc, \n",
    "        'network':network,\n",
    "        'inp':inp, \n",
    "        'inp_mask':inp_mask,\n",
    "        'target':target,\n",
    "        'train_fn':train_fn, \n",
    "        'test_fn':test_fn\n",
    "           } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейронная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В простейшем случае мы будем использовать сеть, которая считывает входную последовательность, и выдает результат только в самом конце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_network(input_var=None, input_mask=None, emb_size = 40, n_hidden = 100):\n",
    "    \"\"\"Функция строит простейшую рекуррентную сеть, которая состоит из следующих слоев:\n",
    "    \n",
    "    1. Входной слой размера [BATCH_SIZE, MAX_LEN]. \n",
    "    2. Embedding для перевода кодировки символов в нормальное представление: VOCAB_SIZE -> emb_size\n",
    "    3. Входной слой для маски размера [BATCH_SIZE, MAX_LEN]\n",
    "    4. Рекуррентный слой c n_hidden элементов на скрытом слое:\n",
    "        * этому слою кроме обычного входа нужно подавать еще и mask для правильной работы \n",
    "            с последовательностями разной длины\n",
    "        * из этого слоя нам нужно только выход в последний момент времени, \n",
    "            его можно извлечь с помощью only_return_final\n",
    "    5. Обычный полносвязный слой для бинарной классификации с sigmoid в качестве нелинейности\n",
    "    \n",
    "    Чтобы в дальнейшем мы могли запускать сеть, например, на одной последовательности, \n",
    "    для входного слоя и маски стоит прописывать shape=(None, None)\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    l_input = lasagne.layers.InputLayer(shape=(BATCH_SIZE,MAX_LEN),input_var=input_var)\n",
    "    l_embedding = lasagne.layers.EmbeddingLayer(l_input, input_size=VOCAB_SIZE,output_size=emb_size)\n",
    "    l_mask_input = lasagne.layers.InputLayer(shape=(BATCH_SIZE, MAX_LEN),input_var=input_mask)\n",
    "    l_rnn = lasagne.layers.RecurrentLayer(l_embedding,num_units=n_hidden,mask_input=l_mask_input,only_return_final=True)\n",
    "    network = lasagne.layers.DenseLayer(l_rnn,num_units=2,nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(train_data, test_data, emb_size, n_hidden, show = False):\n",
    "    \"\"\"Функция обучает нейросеть по данным train_data + контролирует процесс по качеству на test_data\n",
    "    Следует обратить внимание на следующее:\n",
    "    1. Сеть будем учить NUM_EPOCHS эпох, в каждой из столько батчей, сколько есть в train_data\n",
    "    2. Перед каждой эпохой желательно перемешивать данные с помощью shuffle\n",
    "    3. Для того, чтобы следить за процессом обучения будем считать средний loss и \n",
    "        среднюю точность классификации на всех батчах трейна и теста и сохранять жти данные \n",
    "        в соответствующие массивы. \n",
    "    4. Перед тем, как делать шаг по градиенту, будем ограничивать градиент по норме\n",
    "        с помощью функции lasagne.updates.total_norm_constraint с ограничением на норму GRAD_CLIP\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Prepare data ...\")\n",
    "    train_x, train_mask, train_y = train_data['x'], train_data['mask'],train_data['y']\n",
    "    test_x, test_mask, test_y = test_data['x'], test_data['mask'],test_data['y']\n",
    "    \n",
    "    train_size = len(train_y)\n",
    "    test_size = len(test_y)\n",
    "    num_train_batches = train_size / BATCH_SIZE\n",
    "    num_test_batches = test_size / BATCH_SIZE\n",
    "    train_err=np.zeros(NUM_EPOCHS)\n",
    "    train_acc=np.zeros(NUM_EPOCHS)\n",
    "    test_err=np.zeros(NUM_EPOCHS)\n",
    "    test_acc=np.zeros(NUM_EPOCHS)\n",
    "        \n",
    "    print(\"Building network ...\")\n",
    "    # TODO\n",
    "    target_values = T.ivector('target_output')\n",
    "    input_x = T.matrix()\n",
    "    input_mask = T.matrix()\n",
    "    network = build_network(input_var=input_x, input_mask=input_mask)\n",
    "    print(\"The network has {} params\".format(lasagne.layers.count_params(network)))\n",
    "    \n",
    "    # Функции для loss, updates, train_fn и logprobs_fn\n",
    "    # В качетсве loss стоит взять обычную бинарную cross-entropy\n",
    "    # Для более устойчивого вычисления loss стоит обрезать предсказание \n",
    "    # перед подсчетом loss: T.clip(prediction,1e-7,1-1e-7)\n",
    "    # В качестве метода оптимизации рекомендуется использовать adam\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    network_output = lasagne.layers.get_output(network)\n",
    "    T.clip(network_output,1e-7,1-1e-7)\n",
    "    loss = lasagne.objectives.binary_crossentropy(network_output, target_values)\n",
    "    loss = loss.mean()\n",
    "    acc = T.mean(T.eq(network_output, target_values))\n",
    "    \n",
    "    weights = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    all_grads = T.grad(loss, all_params)\n",
    "    scaled_grads, norm = lasagne.updates.total_norm_constraint(all_grads, GRAD_CLIP)\n",
    "    updates = lasagne.updates.adam(scaled_grads, weights,learning_rate=LEARNING_RATE)\n",
    "    \n",
    "    train_fn = theano.function([train_x,train_mask, train_y], [loss, acc], updates=updates)\n",
    "    test_fn = theano.function([test_x,test_mask, test_y], [loss, acc])\n",
    "    \n",
    "    inp_mask = None\n",
    "    inp = None\n",
    "    print(\"Training ...\")\n",
    "    for epoch in xrange(NUM_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        # TODO\n",
    "        train_x, train_mask, train_y = shuffle(train_x, train_mask, train_y)\n",
    "        loss_val = 0.0\n",
    "        acc_val = 0.0\n",
    "        for batch in xrange(num_train_batches):\n",
    "            batch_train_x = train_x[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "            batch_mask_x = train_mask[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "            batch_train_y = train_y[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "            batch_loss, batch_acc = train_fn(batch_train_x, batch_mask_x, batch_train_y)\n",
    "            loss_val += batch_loss\n",
    "            acc_val += batch_acc\n",
    "        train_err[epoch] = loss_val/num_train_batches\n",
    "        train_acc[epoch] = acc_val/num_train_batches\n",
    "        \n",
    "        for batch in xrange(num_test_batches):\n",
    "            batch_test_x = test_x[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "            batch_mask_x = test_mask[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "            batch_test_y = test_y[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "            batch_loss, batch_acc = train_fn(batch_test_x, batch_mask_x, batch_test_y)\n",
    "            loss_val += batch_loss\n",
    "            acc_val += batch_acc\n",
    "        test_err[epoch] = loss_val/num_train_batches\n",
    "        test_acc[epoch] = acc_val/num_train_batches\n",
    "        \n",
    "        print(\"Epoch {} \\t loss / accuracy test = {:.4f}, {:.4f} \\t train = {:.4f}, {:.4f} \\t time = {:.2f}s\".\n",
    "              format(epoch, test_err[epoch],test_acc[epoch], \n",
    "                     train_err[epoch],  train_acc[epoch],time.time() - start_time))\n",
    "             \n",
    "    return pack(train_err, train_acc, test_err, test_acc, network, inp, inp_mask, target, train_fn, test_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем, как запускать обучение большой сети на большое число эпох, проверьте, что маленькая сеть выдает вменяемые результаты: качество больше 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data ...\n",
      "Building network ...\n",
      "The network has 15642 params\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "index must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-756a33838fc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-1bc28b7caca9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, test_data, emb_size, n_hidden, show)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mnetwork_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjectives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parkin/.local/lib/python2.7/site-packages/lasagne/layers/helper.pyc\u001b[0m in \u001b[0;36mget_output\u001b[0;34m(layer_or_layers, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m                                  \u001b[0;34m\"mapping this layer to an input expression.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                                  % layer)\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mall_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_for\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parkin/.local/lib/python2.7/site-packages/lasagne/layers/embedding.pyc\u001b[0m in \u001b[0;36mget_output_for\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/parkin/.local/lib/python2.7/site-packages/theano/tensor/var.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    540\u001b[0m                             \u001b[0mTensorVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorConstant\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                             theano.tensor.sharedvar.TensorSharedVariable))):\n\u001b[0;32m--> 542\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvanced_subtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parkin/.local/lib/python2.7/site-packages/theano/tensor/var.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, mode)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;31m# COPYING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parkin/.local/lib/python2.7/site-packages/theano/tensor/subtensor.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(a, indices, axis, mode)\u001b[0m\n\u001b[1;32m   2390\u001b[0m                 [a.shape[:axis], indices.shape, a.shape[axis + 1:]])\n\u001b[1;32m   2391\u001b[0m         \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2392\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/parkin/.local/lib/python2.7/site-packages/theano/tensor/subtensor.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(a, indices, axis, mode)\u001b[0m\n\u001b[1;32m   2366\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0madvanced_subtensor1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2368\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0madvanced_subtensor1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parkin/.local/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \"\"\"\n\u001b[1;32m    603\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'return_list'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'off'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/parkin/.local/lib/python2.7/site-packages/theano/tensor/subtensor.pyc\u001b[0m in \u001b[0;36mmake_node\u001b[0;34m(self, x, ilist)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0milist_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0milist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0milist_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'uin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index must be integers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0milist_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index must be vector'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: index must be integers"
     ]
    }
   ],
   "source": [
    "model = train(train_data, test_data, 30, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим что из этого вышло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(name, model):\n",
    "    \"\"\"Функция выдает предсказание обученной модели model для имени name.\n",
    "    Предсказание - число из [0,1] - вероятность того, что имя женское\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = set(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new name\n",
      "It's male name\n",
      "[ 0.04011425]\n"
     ]
    }
   ],
   "source": [
    "name = 'Yaroslav'\n",
    "if name.lower() in dataset:\n",
    "    print 'This name is in our dataset'\n",
    "else:\n",
    "    print 'This is a new name'\n",
    "pred = predict(name, model)\n",
    "if pred>=0.5:\n",
    "    print \"It's female name\"\n",
    "else:\n",
    "    print \"It's male name\"\n",
    "print pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new name\n",
      "It's female name\n",
      "[ 0.99993134]\n"
     ]
    }
   ],
   "source": [
    "name = 'Polina'\n",
    "if name.lower() in dataset:\n",
    "    print 'This name is in our dataset'\n",
    "else:\n",
    "    print 'This is a new name'\n",
    "pred = predict(name, model)\n",
    "if pred>=0.5:\n",
    "    print \"It's female name\"\n",
    "else:\n",
    "    print \"It's male name\"\n",
    "print pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительные пункты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Обучение более сложной модели и контроль переобучения. Попробуйте подобрать хорошую модель RNN для данной задачи. Для этого проанализируйте качество работы модели в зависимости от ее размеров, попробуйте использовать многослойную сеть. Также нужно проконтролировать переобучение моделей. Для этого можно выделить тестовый кусок из текста и смотреть на то, как меняется loss на нем в процессе обучения. Если на графиках видно переобучение, то стоит добавить dropout слои в модель (обычный dropout до, между и после рекуррентных слоев). При использовании дропаута на стадии предсказания для нового объекта нужно ставить флаг deterministic=True.\n",
    "2. Другая архитектура 1. Попробуйте использовать не только состоянию скрытых переменных в последний момент времени, а усреднение/максимум значений скрытых переменных во все моменты времени. Попробуйте двунаправленную сеть при таком подходе. \n",
    "3. Другая архитектура 2. Попробуйте использовать не только состоянию скрытых переменных в последний момент времени, а сумму значений скрытых переменных во все моменты времени с коэффициентами attention. Попробуйте двунаправленную сеть при таком подходе. Attention коэффициент для определенного момента времени может представлять собой просто линейную комбинацию значений скрытых переменных в этот момент времени с обучаемыми весами.\n",
    "3. Визуализация. Попробуйте провизуализировать результаты. Например, для стандартной архитектуры можно посмотреть на изменение предсказания во времени: на каких элементах предсказание значительнее всего изменяется в сторону одного или другого класса? При использовании схемы из 2/3 пункта, можно смотреть на вклад каждого момента времени в результат. Так как после рекуррентного слоя у нас стоит просто линейный классификатор, то можно посмотреть, что выдает этот классификатор при применении к скрытым переменным в каждый момент времени. Таким образом выделяться те буквы, которые голосуют за один класс и те, которые голосуют за другой.\n",
    "4. Batchnorm и Layernorm. Запрограммируйте RNN c layer normalization из статьи [Lei Ba et al., 2016]. Поэкспериментируйте с применением обычной batch normalization и layer normalization, сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
